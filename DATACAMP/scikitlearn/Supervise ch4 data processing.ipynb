{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.__len__ of       instance_id           artist_name            track_name  popularity  \\\n",
       "0         32894.0              Röyksopp  Röyksopp's Night Out        27.0   \n",
       "1         46652.0  Thievery Corporation      The Shining Path        31.0   \n",
       "2         30097.0        Dillon Francis             Hurricane        28.0   \n",
       "3         62177.0              Dubloadz                 Nitro        34.0   \n",
       "4         24907.0           What So Not      Divide & Conquer        32.0   \n",
       "...           ...                   ...                   ...         ...   \n",
       "9995      52940.0     POLKADOT STINGRAY                   有頂天        39.0   \n",
       "9996      34233.0              flumpool      Hoshi Ni Negaiwo        33.0   \n",
       "9997      78473.0          Kevin Penkin                Mirage        21.0   \n",
       "9998      87518.0       BUMP OF CHICKEN                 ハルジオン        44.0   \n",
       "9999      41509.0            Hachioji P  Yeah! Yeah!! Yeah!!!        14.0   \n",
       "\n",
       "      acousticness  danceability  duration_ms  energy  instrumentalness key  \\\n",
       "0         0.004680         0.652         -1.0   0.941          0.792000  A#   \n",
       "1         0.012700         0.622     218293.0   0.890          0.950000   D   \n",
       "2         0.003060         0.620     215613.0   0.755          0.011800  G#   \n",
       "3         0.025400         0.774     166875.0   0.700          0.002530  C#   \n",
       "4         0.004650         0.638     222369.0   0.587          0.909000  F#   \n",
       "...            ...           ...          ...     ...               ...  ..   \n",
       "9995      0.030100         0.504     302080.0   0.860          0.000038  F#   \n",
       "9996      0.000456         0.517     258480.0   0.868          0.000594   B   \n",
       "9997      0.106000         0.527     134787.0   0.262          0.167000   F   \n",
       "9998      0.030300         0.271     275933.0   0.969          0.000490  C#   \n",
       "9999      0.020000         0.573     226374.0   0.921          0.000004  F#   \n",
       "\n",
       "      liveness  loudness   mode  speechiness               tempo  \\\n",
       "0        0.115    -5.201  Minor       0.0748             100.889   \n",
       "1        0.124    -7.043  Minor       0.0300  115.00200000000001   \n",
       "2        0.534    -4.617  Major       0.0345             127.994   \n",
       "3        0.157    -4.498  Major       0.2390             128.014   \n",
       "4        0.157    -6.266  Major       0.0413             145.036   \n",
       "...        ...       ...    ...          ...                 ...   \n",
       "9995     0.254    -4.059  Major       0.1380             134.143   \n",
       "9996     0.183    -3.696  Minor       0.0343              136.98   \n",
       "9997     0.146   -17.812  Major       0.0394             125.023   \n",
       "9998     0.301    -2.539  Major       0.0678  180.05700000000002   \n",
       "9999     0.325    -3.841  Major       0.0734             135.029   \n",
       "\n",
       "     obtained_date  valence music_genre  \n",
       "0            4-Apr   0.7590  Electronic  \n",
       "1            4-Apr   0.5310  Electronic  \n",
       "2            4-Apr   0.3330  Electronic  \n",
       "3            4-Apr   0.2700  Electronic  \n",
       "4            4-Apr   0.3230  Electronic  \n",
       "...            ...      ...         ...  \n",
       "9995         4-Apr   0.8310       Anime  \n",
       "9996         4-Apr   0.5900       Anime  \n",
       "9997         4-Apr   0.0394       Anime  \n",
       "9998         4-Apr   0.4800       Anime  \n",
       "9999         4-Apr   0.5990       Anime  \n",
       "\n",
       "[10000 rows x 18 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "music_df=pd.read_csv('music_genre.csv')\n",
    "music_df=music_df[:10000]\n",
    "music_df.head()\n",
    "music_df.__len__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Got It!\n",
    "1. Preprocessing data\n",
    "Welcome to the final chapter of the course!\n",
    "\n",
    "2. scikit-learn requirements\n",
    "Recall that scikit-learn requires numeric data, with no missing values. All the data that we have used so far has been in this format. However, with real-world data, this will rarely be the case, and instead we need to preprocess our data before we can build models.\n",
    "\n",
    "3. Dealing with categorical features\n",
    "Say we have a dataset containing categorical features, such as color. As these are not numeric, scikit-learn will not accept them and we need to convert them into numeric features. We achieve this by splitting the feature into multiple binary features called dummy variables, one for each category. Zero means the observation was not that category, while one means it was.\n",
    "\n",
    "4. Dummy variables\n",
    "Say we are working with a music dataset that has a genre feature with ten values such as Electronic, Hip-Hop, and Rock.\n",
    "\n",
    "5. Dummy variables\n",
    "We create binary features for each genre. As each song has one genre, each row will have a 1 in one of the ten columns and zeros in the rest. If a song is not any of the first nine genres, then implicitly, it is a rock song. That means we only need nine features, so we can\n",
    "\n",
    "6. Dummy variables\n",
    "delete the Rock column. If we do not do this, we are duplicating information, which might be an issue for some models.\n",
    "\n",
    "7. Dealing with categorical features in Python\n",
    "To create dummy variables we can use scikit-learn's OneHotEncoder, or pandas' get_dummies. We will use get_dummies.\n",
    "\n",
    "8. Music dataset\n",
    "We will be working with a music dataset in this chapter, for both classification and regression problems. Initially, we will build a regression model using all features in the dataset to predict song popularity. There is one categorical feature, genre, with ten possible values.\n",
    "\n",
    "9. EDA w/ categorical feature\n",
    "This box plot shows how popularity varies by genre. Let's encode this feature using dummy variables.\n",
    "\n",
    "10. Encoding dummy variables\n",
    "We import pandas, read in the DataFrame, and call pd-dot-get_dummies, passing the categorical column. As we only need to keep nine out of our ten binary features, we can set the drop_first argument to True. Printing the first five rows, we see pandas creates nine new binary features. The first song is Jazz, and the second is Rap, indicated by a 1 in the respective columns. To bring these binary features back into our original DataFrame we can use pd-dot-concat, passing a list containing the music DataFrame and our dummies DataFrame, and setting axis equal to one. Lastly, we can remove the original genre column using df-dot-drop, passing the column, and setting axis equal to one.\n",
    "\n",
    "11. Encoding dummy variables\n",
    "If the DataFrame only has one categorical feature, we can pass the entire DataFrame, thus skipping the step of combining variables. If we don't specify a column, the new DataFrame's binary columns will have the original feature name prefixed, so they will start with genre-underscore - as shown here. Notice the original genre column is automatically dropped. Once we have dummy variables, we can fit models as before.\n",
    "\n",
    "12. Linear regression with dummy variables\n",
    "Using the music_dummies DataFrame, the process for creating training and test sets remains unchanged. To perform cross-validation we then create a KFold object, instantiate a linear regression model, and call cross_val_score. We set scoring equal to neg_mean_squared_error, which returns the negative MSE. This is because scikit-learn's cross-validation metrics presume a higher score is better, so MSE is changed to negative to counteract this. We can calculate the training RMSE by taking the square root and converting to positive, achieved by calling numpy-dot-square-root and passing our scores with a minus sign in front.\n",
    "\n",
    "13. Let's practice!\n",
    "Now let's practice working with categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df,drop_first=True)\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))\n",
    "# Create X and y\n",
    "X = music_dummies.drop('popularity',axis=1).values\n",
    "y = music_dummies['popularity'].values\n",
    "kf=KFold(n_splits=6,shuffle=True)\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instance_id         0\n",
       "artist_name         0\n",
       "track_name          0\n",
       "popularity          0\n",
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "key                 0\n",
       "liveness            0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "obtained_date       0\n",
       "valence             0\n",
       "music_genre         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Got It!\n",
    "1. Handling missing data\n",
    "Now let's look at how to handle missing data.\n",
    "\n",
    "2. Missing data\n",
    "When there is no value for a feature in a particular row, we call it missing data. This can happen because there was no observation or the data might be corrupt. Whatever the reason, we need to deal with it.\n",
    "\n",
    "3. Music dataset\n",
    "Previously we worked with a modified music dataset. Now let's inspect the original version, which contains one thousand rows. We do this by chaining pandas' dot-isna with dot-sum and dot-sort_values. Each feature is missing between 8 and 200 values!\n",
    "\n",
    "4. Dropping missing data\n",
    "A common approach is to remove missing observations accounting for less than 5% of all data. To do this, we use pandas' dot-dropna method, passing a list of columns with less than 5% missing values to the subset argument. If there are missing values in our subset column, the entire row is removed. Rechecking the DataFrame, we see fewer missing values.\n",
    "\n",
    "5. Imputing values\n",
    "Another option is to impute missing data. This means making an educated guess as to what the missing values could be. We can impute the mean of all non-missing entries for a given feature. We can also use other values like the median. For categorical values we commonly impute the most frequent value. Note we must split our data before imputing to avoid leaking test set information to our model, a concept known as data leakage.\n",
    "\n",
    "6. Imputation with scikit-learn\n",
    "Here is a workflow for imputation to predict song popularity. We import SimpleImputer from sklearn-dot-impute. As we will use different imputation methods for categorical and numeric features, we first split them, storing as X_cat and X_num respectively, along with our target array as y. We create categorical training and test sets. We repeat this for the numeric features. By using the same value for the random_state argument, the target arrays' values remain unchanged. To impute missing categorical values we instantiate a SimpleImputer, setting strategy as most frequent. By default, SimpleImputer expects NumPy-dot-NaN to represent missing values. Now we call dot-fit_transform to impute the training categorical features' missing values! For the test categorical features, we call dot-transform.\n",
    "\n",
    "7. Imputation with scikit-learn\n",
    "For our numeric data, we instantiate another imputer. By default, it fills values with the mean. We fit and transform the training features, and transform the test features. We then combine our training data using numpy-dot-append, passing our two arrays, and set axis equal to 1. We repeat this for our test data. Due to their ability to transform our data, imputers are known as transformers.\n",
    "\n",
    "8. Imputing within a pipeline\n",
    "We can also impute using a pipeline, which is an object used to run a series of transformations and build a model in a single workflow. To do this, we import Pipeline from sklearn-dot-pipeline. Here we perform binary classification to predict whether a song is rock or another genre. We drop missing values accounting for less than five percent of our data. We convert values in the genre column, which will be the target, to a 1 if Rock, else 0, using numpy-dot-where. We then create X and y.\n",
    "\n",
    "9. Imputing within a pipeline\n",
    "To build a pipeline we construct a list of steps containing tuples with the step names specified as strings, and instantiate the transformer or model. We pass this list when instantiating a Pipeline. We then split our data, and fit the pipeline to the training data, as with any other model. Finally, we compute accuracy. Note that, in a pipeline, each step but the last must be a transformer.\n",
    "\n",
    "10. Let's practice!\n",
    "Now let's create a pipeline to handle missing data and build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_cat = music_df[\"genre\"].values.reshape(-1, 1)\n",
    "X_num = music_df.drop([\"genre\", \"popularity\"], axis=1).values\n",
    "y = music_df[\"popularity\"].values\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size=0.2,random_state=12)    \n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y, test_size=0.2,random_state=12)\n",
    "imp_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
    "X_test_cat = imp_cat.transform(X_test_cat)\n",
    "\n",
    "imp_num = SimpleImputer()\n",
    "X_train_num = imp_num.fit_transform(X_train_num)\n",
    "X_test_num = imp_num.transform(X_test_num)\n",
    "X_train = np.append(X_train_num, X_train_cat, axis=1)\n",
    "X_test = np.append(X_test_num, X_test_cat, axis=1)\n",
    "#Imputersareknownastransformers\n",
    "#IMPUTING IN PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a pipeline \n",
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=.3,random_state=21)\n",
    "imp_mean=SimpleImputer(strategy='mean')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Got It!\n",
    "1. Centering and scaling\n",
    "Data imputation is one of several important preprocessing steps for machine learning. Now let's cover another: centering and scaling our data.\n",
    "\n",
    "2. Why scale our data?\n",
    "Let's use df-dot-describe to check out the ranges of some of our feature variables in the music dataset. We see that the ranges vary widely: duration_ms ranges from zero to one-point-six-two million, speechiness contains only decimal places, and loudness only has negative values!\n",
    "\n",
    "3. Why scale our data?\n",
    "Many machine learning models use some form of distance to inform them, so if we have features on far larger scales, they can disproportionately influence our model. For example, KNN uses distance explicitly when making predictions. For this reason, we actually want features to be on a similar scale. To achieve this, we can normalize or standardize our data, often referred to as scaling and centering.\n",
    "\n",
    "4. How to scale our data\n",
    "There are several ways to scale our data: given any column, we can subtract the mean and divide by the variance so that all features are centered around zero and have a variance of one. This is called standardization. We can also subtract the minimum and divide by the range of the data so the normalized dataset has minimum zero and maximum one. Or, we can center our data so that it ranges from -1 to 1 instead. In this video, we will perform standardization, but scikit-learn has functions available for other types of scaling.\n",
    "\n",
    "5. Scaling in scikit-learn\n",
    "To scale our features, we import StandardScaler from sklearn-dot-preprocessing. We create our feature and target arrays. Before scaling, we split our data to avoid data leakage. We then instantiate a StandardScaler object, and call its fit_transform method, passing our training features. Next, we use scaler-dot-transform on the test features. Looking at the mean and standard deviation of the columns of both the original and scaled data verifies the change has taken place.\n",
    "\n",
    "6. Scaling in a pipeline\n",
    "We can also put a scaler in a pipeline! Here we build a pipeline object to scale our data and use a KNN model with six neighbors. We then split our data, fit the pipeline to our training set, and predict on our test set. Computing the accuracy yields a result of zero-point-eight-one. Let's compare this to using unscaled data.\n",
    "\n",
    "7. Comparing performance using unscaled data\n",
    "Here we fit a KNN model to our unscaled training data and print the accuracy. It is only zero-point-five-three, so just by scaling our data we improved accuracy by over 50 percent!\n",
    "\n",
    "8. CV and scaling in a pipeline\n",
    "Let's also look at how we can use cross-validation with a pipeline. We first build our pipeline. We then specify our hyperparameter space by creating a dictionary: the keys are the pipeline step name followed by a double underscore, followed by the hyperparameter name. The corresponding value is a list or an array of the values to try for that particular hyperparameter. In this case, we are tuning n_neighbors in the KNN model. Next we split our data into training and test sets. We then perform a grid search over our parameters by instantiating the GridSearchCV object, passing our pipeline and setting the param_grid argument equal to parameters. We then fit it to our training data. Lastly, we make predictions using our test set.\n",
    "\n",
    "9. Checking model parameters\n",
    "Printing GridSearchCV's best_score_ attribute, we see the score is very slightly better than our previous model's performance. Printing the best parameters, the optimal model has 12 neighbors.\n",
    "\n",
    "10. Let's practice!\n",
    "Now let's incorporate scaling into our supervised learning workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\defaultuser0.LAPTOP-LRB3T941\\Documents\\Tensorflow\\DATACAMP\\Supervise ch4 data processing.ipynb Cell 12\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/defaultuser0.LAPTOP-LRB3T941/Documents/Tensorflow/DATACAMP/Supervise%20ch4%20data%20processing.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/defaultuser0.LAPTOP-LRB3T941/Documents/Tensorflow/DATACAMP/Supervise%20ch4%20data%20processing.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Create pipeline steps\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/defaultuser0.LAPTOP-LRB3T941/Documents/Tensorflow/DATACAMP/Supervise%20ch4%20data%20processing.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m steps \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m\"\u001b[39m, StandardScaler()),\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/defaultuser0.LAPTOP-LRB3T941/Documents/Tensorflow/DATACAMP/Supervise%20ch4%20data%20processing.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m          (\u001b[39m\"\u001b[39m\u001b[39mlasso\u001b[39m\u001b[39m\"\u001b[39m, Lasso(alpha\u001b[39m=\u001b[39m\u001b[39m.5\u001b[39m))]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/defaultuser0.LAPTOP-LRB3T941/Documents/Tensorflow/DATACAMP/Supervise%20ch4%20data%20processing.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Instantiate the pipeline\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/defaultuser0.LAPTOP-LRB3T941/Documents/Tensorflow/DATACAMP/Supervise%20ch4%20data%20processing.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(steps)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the steps\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)\n",
    "\n",
    "#estimator.get_params().keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Got It!\n",
    "1. Evaluating multiple models\n",
    "We've covered all parts of the supervised learning workflow. But how do we decide which model to use in the first place?\n",
    "\n",
    "2. Different models for different problems\n",
    "This is a complex question, and the answer depends on our situation. However, there are some principles that can guide us when making this decision. The size of our dataset plays a role. Fewer features means a simpler model, and can reduce training time. Also, some models, such as Artificial Neural Networks, require a lot of data to perform well. We may need an interpretable model, so we can explain to stakeholders how predictions were made. An example is linear regression, where we can calculate and interpret the model coefficients. Alternatively, flexibility might be important to get the most accurate predictions. Generally, flexible models make fewer assumptions about the data; for example, a KNN model does not assume a linear relationship between the features and the target.\n",
    "\n",
    "3. It's all in the metrics\n",
    "Notice that scikit-learn allows the same methods to be used for most models. This makes it easy to compare them! Regression models can be evaluated using the root mean squared error, or the R-squared value. Likewise, classification models can all be analyzed using accuracy, a confusion matrix and its associated metrics, or the ROC AUC. Therefore, one approach is to select several models and a metric, then evaluate their performance without any form of hyperparameter tuning.\n",
    "\n",
    "4. A note on scaling\n",
    "Recall that the performance of some models, such as KNN, linear regression, and logistic regression, are affected by scaling our data. Therefore, it is generally best to scale our data before evaluating models out of the box.\n",
    "\n",
    "5. Evaluating classification models\n",
    "We will evaluate three models for binary classification of song genre: KNN, logistic regression, and a new model called a decision tree classifier. We import our required modules, including DecisionTreeClassifier from sklearn-dot-tree. The workings of decision trees are outside the scope of this course, but the steps for building this model are the same as for other models in scikit-learn. As usual, we create our feature and target arrays, then split our data. We then scale our features using the scaler's dot-fit_transform method on the training set, and the dot-transform method on the test set.\n",
    "\n",
    "6. Evaluating classification models\n",
    "We create a dictionary with our model names as strings for the keys, and instantiate models as the dictionary's values. We also create an empty list to store the results. Now we loop through the models in our models dictionary, using its dot-values method. Inside the loop, we instantiate a KFold object. Next we perform cross-validation, using the model being iterated, along with our scaled training features, and target training array. We set cv equal to our kfold variable. By default, the scoring here will be accuracy. We then append the cross-validation results to our results list. Lastly, outside of the loop, we create a boxplot of our results, and set the labels argument equal to a call of models-dot-keys to retrieve each model's name.\n",
    "\n",
    "7. Visualizing results\n",
    "The output shows us the range of cross-validation accuracy scores. We can also see each model's median cross-validation score, represented by the orange line in each box. We can see logistic regression has the best median score.\n",
    "\n",
    "8. Test set performance\n",
    "To evaluate on the test set we loop through the names and values of the dictionary using the dot-items method. Inside the loop we fit the model, calculate accuracy, and print it. Logistic regression performs best for this problem if we are using accuracy as the metric.\n",
    "\n",
    "9. Let's practice!\n",
    "Now let's choose which models to optimize for our supervised learning problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled,y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
